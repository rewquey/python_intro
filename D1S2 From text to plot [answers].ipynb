{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, after lunch: From text files to plots\n",
    "\n",
    "In this session, we will learn how to read text files and extract relevant information. We will also create plots using the python library ``matplotlib``.\n",
    "\n",
    "We'll first manually parse a text file in order to understand what needs to happen, before we learn to avoid most of the repetitive code by making use of module functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First example: Weather observations from near Snøheim\n",
    "\n",
    "Snøheim is a DNT hut close to Snøhetta, Dovrefjell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('d1s2/Dovre1-Snoheim.txt', 'r')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines[0]) # first line of the file\n",
    "print(lines[-1]) # final line of the file, note the negative indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing\n",
    "Reading a file with `readlines()` gives us a list of strings, one for each line of the file. In this case each line is composed of a date and time followed by four floating point numbers. \n",
    "\n",
    "In order to do anything interesting with the data we need to interpret the strings as dates and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import dateutil.parser # powerful datetime string parsing\n",
    "\n",
    "# store data in lists, one for each column of the file\n",
    "dates = []\n",
    "temp = []\n",
    "ff = []\n",
    "dd = []\n",
    "for line in lines:\n",
    "    line = line.split() # splits a string into substrings by spaces\n",
    "    datetime_string = ' '.join(line[:2]) # the first two substrings contain time and date\n",
    "    dates.append(dt.strptime(datetime_string, '%d.%m.%Y %H:%M:%S'))\n",
    "    # dates.append(dateutil.parser.parse(datetime_string)) # parsing without explicit format string\n",
    "    temp.append(float(line[3])) # convrts a string into a float\n",
    "    ff.append(float(line[4]))\n",
    "    dd.append(float(line[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dates), dates[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Read and interpret the tile rro_Bulken.txt\n",
    "For this exercise you are going to read a file and do some analysis yourself. Start by printing the file to become familiar with its format. Then write a program to answer the following questions:\n",
    "* On how many days did the runoff exceed 300 m³/s?\n",
    "* On how many days did the runoff exceed the climatological median flow and the 75-percentile?\n",
    "\n",
    "Hint: You can use ``sum`` to count the number of ``True`` entries in a list of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('d1s2/rro_Bulken.txt', 'r', encoding='latin1')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "dates = []\n",
    "runoff = []\n",
    "p50 = []\n",
    "p75 = []\n",
    "for line in lines[2:]:\n",
    "    line = line.split()\n",
    "    dates.append(dt.strptime(line[0], '%d%m%Y'))\n",
    "    if line[2] == '----':\n",
    "        line[2] = 'NaN'\n",
    "    runoff.append(float(line[2]))\n",
    "    p50.append(float(line[4]))\n",
    "    p75.append(float(line[3]))\n",
    "\n",
    "l = len(runoff)\n",
    "print('Exceed 300 m3/s:', sum([r > 300 for r in runoff]), 'of', l)\n",
    "print('Exceed median:', sum([r > m for r, m in zip(runoff, p50)]), 'of', l)\n",
    "print('Exceed 75p:', sum([r > p for r, p in zip(runoff, p75)]), 'of', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all works fine, but already with this example it became quite repetitive! There must be a simpler solution to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading text files using numpy.loadtxt\n",
    "\n",
    "The name of the function sounds quite promising, so let's give it a naive shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('d1s2/Dovre1-Snoheim.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did not work all too well!\n",
    "\n",
    "The reason is that ``numpy.loadtxt`` tries to convert all values in the matrix to numbers. So we somehow need to convert date strings like the quoted ``'30.06.2012'`` to a number to make this work.\n",
    "\n",
    "Idea: We could count the number of seconds since a reference date to represent the date as a number. Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_REF = dt(1970,1,1)\n",
    "def parse_time(ibytes):\n",
    "    ''' Converts a bytes object into a float representing a date and time\n",
    "    \n",
    "    We need to return a float instead of a datetime, as the variable type \n",
    "    within a numpy array needs to be homogeneous.\n",
    "    \n",
    "    To convert the date to a float, we return the number of seconds since \n",
    "    a reference time given by DT_REF.\n",
    "    '''\n",
    "    \n",
    "    # Convert bytes to string\n",
    "    istr = ibytes.decode('latin1')\n",
    "    # Convert string to datetime\n",
    "    date = dt.strptime(istr, '%d.%m.%Y %H:%M:%S')\n",
    "    # Return number of seconds between DT_REF and date\n",
    "    return (date - DT_REF).total_seconds()\n",
    "\n",
    "print(parse_time(b'30.06.2012 14:16:00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this function as a converter from string to number. Further, as the date format in the text file contains a space, we'll need to tell ``numpy.loadtxt`` to interpret only tabs as column separators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('d1s2/Dovre1-Snoheim.txt', delimiter='\\t', converters={\n",
    "    0: parse_time\n",
    "})\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works, but but we will then need a way to convert the number back to a ``datetime`` object. Here the ``timedelta`` can help, because we can then just add the given number of seconds on the reference date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta as td\n",
    "\n",
    "def float_to_date(val):\n",
    "    ''' Convert a float back to datetime \n",
    "    \n",
    "    Consistently to ``parse_time'', ``val'' is expected to contain the\n",
    "    number of seconds since DT_REF. We can then use the timedelta object to \n",
    "    add the given number of seconds to DT_REF and return the resulting\n",
    "    ``datetime'' object.\n",
    "    '''\n",
    "    return DT_REF + td(0,val)\n",
    "\n",
    "print(data[0,0], float_to_date(data[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, manually parsing the time like shown here is quite tedious and error-prone. Fortunately, there is a stable and well-tested version available through ``matplotlib.dates``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import strpdate2num, num2date\n",
    "data = np.loadtxt('d1s2/Dovre1-Snoheim.txt', encoding='utf8', delimiter='\\t', converters={\n",
    "    0: strpdate2num('%d.%m.%Y %H:%M:%S')\n",
    "})\n",
    "print(data.shape)\n",
    "print(data[0,0], num2date(data[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting what we got\n",
    "\n",
    "First let's extract the data that we want to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dates\n",
    "dates = [num2date(date) for date in data[:,0]]\n",
    "# Extract temperature and wind speed, and make them available through easy-to-remember names\n",
    "airtemp = data[:,2]\n",
    "windspeed = data[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data to be plotted ready, let's make our first plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some times it's just as easy as this :)\n",
    "plt.plot(dates, airtemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, there's a lot one could criticise about this plot. The dates are quite illegible, and there's no informaiton on what we're actually showing. So let's adapt the plot, and add this info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.plot(dates, airtemp)\n",
    "plt.ylabel('Temperature [°C]') # Adding labels is easy\n",
    "\n",
    "# But changing the formatting of the dates is slightly more involved, \n",
    "# because the respective functions is only available through the axes object.\n",
    "ax = plt.gca() # gca: Get Current Axes\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! But then let's also focus on a shorter time period, to better see what's actually going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslice = slice(800, 3000)\n",
    "plt.plot(dates[timeslice], airtemp[timeslice])\n",
    "# has the same effect as\n",
    "# plt.plot(dates[800:3000], airtemp[800:3000])\n",
    "# but avoids the repetition.\n",
    "\n",
    "plt.ylabel('Temperature [°C]')\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add wind speed measurements in the same plot. We're using the right y-axis for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C0': First color of the standard cycle\n",
    "plt.plot(dates[timeslice], airtemp[timeslice], color='C0') \n",
    "ax1 = plt.gca()\n",
    "ax1.set_ylabel('Temperature [°C]', color='C0')\n",
    "# Equivalent to \n",
    "#plt.ylabel('Temperature [°C]', color='C0')\n",
    "# but clearer to read, because the Axes to which we apply the ylabel is explitit\n",
    "\n",
    "# Change the color of the tick label values\n",
    "ax1.tick_params(axis='y', labelcolor='C0')\n",
    "\n",
    "# A new axes object sharing the x-axis with the first\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# 'C1': Second color of the standard cycle\n",
    "ax2.plot(dates[timeslice], windspeed[timeslice], color='C1')\n",
    "ax2.set_ylabel('Wind speed [m/s]', color='C1')\n",
    "#plt.ylabel('Wind speed [m/s]', color='C1')\n",
    "ax2.tick_params(axis='y', labelcolor='C1')\n",
    "\n",
    "# needs to be done after the twinx\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks quite good already, but let's change the Figure size to make the graphs still a bit easier to read. Further, we'll make the graph lines slightly transparent such that the orange line is no longer fully covering the blue one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the figure size \n",
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=96)\n",
    "\n",
    "ax1 = plt.gca()\n",
    "# alpha=1: fully opaque, alpha=0: fully transparent\n",
    "ax1.plot(dates[timeslice], airtemp[timeslice], color='C0', alpha=0.7)\n",
    "ax1.set_ylabel('Temperature [°C]', color='C0') \n",
    "ax1.tick_params(axis='y', labelcolor='C0')\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "ax2.plot(dates[timeslice], windspeed[timeslice], color='C1', alpha=0.7)\n",
    "ax2.set_ylabel('Wind speed [m/s]', color='C1')\n",
    "ax2.tick_params(axis='y', labelcolor='C1')\n",
    "\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Try to recreate the following plot based on the runoff data from Bulken\n",
    "\n",
    " * Use numpy.loadtxt to read the file and parse the dates\n",
    " * You might need to define a custom converter to convert ``'----'`` in the text file to NaN values. The built-in function ``float`` might help, also note that ``float('NaN')`` yields a NaN value.\n",
    " * The shaded area shows the interval between the 25 and the 75 percentile\n",
    " * The functions ``plt.fill_between``, ``plt.semilogy`` and ``plt.legend`` might be helpful \n",
    " * You can use the ``label=value``-keyword argument to most plot commands to provide the labels used in the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_to_NaN(istr):\n",
    "    ''' Convert a string containing a number to a float, interpreting unparsible strings as NaN '''\n",
    "    \n",
    "    try:\n",
    "        val = float(istr)\n",
    "    except ValueError:\n",
    "        val = float('NaN')\n",
    "    \n",
    "    return val\n",
    "\n",
    "data = np.loadtxt('d1s2/rro_Bulken.txt', encoding='latin1', converters={\n",
    "    0: strpdate2num('%d%m%Y'),\n",
    "    1: missing_to_NaN,\n",
    "    2: missing_to_NaN,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [num2date(date) for date in data[:,0]]\n",
    "\n",
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=96)\n",
    "\n",
    "plt.semilogy(dates, data[:,4], color='0.4', label='Median') # Median\n",
    "plt.semilogy(dates, data[:,2], color='C1', label='Observed') # The actual flow\n",
    "plt.fill_between(dates, data[:,3], data[:,5], color='0.85', label='Interquartile range') # 25 and 75-percentile\n",
    "\n",
    "plt.ylabel('Runoff at Bulken [m³/s]')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('d1s2/ex1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension of the exercise: How does that fit with observed precipitation?\n",
    "\n",
    "Likely, you won't be finished with this exercise by the end of the session. So just take this exercise as far as you get. A solution is provided in the answers-notebook, so you can always come back to it later.\n",
    "\n",
    " * Manually parse the input text file. ``numpy.loadtxt`` will not work, because the function does not support footers as present in the file.\n",
    " * Plot daily precipitation amount as bars, first into a separate plot, then add it to the one above.\n",
    " * Extra challenge: Daily rainfall is defined by MetNorway between 06 UTC the preceeding day to 06 UTC of the given day. Make sure that the precipitation bars are located such along the time axis that the period in which the precipitation is observed matches the time interval covered by the bar.\n",
    " \n",
    "Some hints that might help along the way.\n",
    "\n",
    " * You can create bar plots with ``plt.bar``. The width of the bars can be changed by the ``width=value``-keyword argument, which with time date takes a value in the unit of days.\n",
    " * You might encounter a mismatch between timezone-aware and timezone-agnostic datetime objects. You can create a datetime object with time zone information using the ``pytz`` module, for example by ``date = dt(2018,9,15,tzinfo=pytz.utc)``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step: Reading and parsing the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual parsing necessary, np.loadtxt does not support footers\n",
    "f = open('d1s2/rr24_Bulken.txt', encoding='utf8')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "dates_start = [] # beginning of the observation intervals\n",
    "daily_precip = [] # observed values\n",
    "# Skip 21 header rows and 12 footer rows\n",
    "for row in lines[21:-12]:\n",
    "    row = row.split()\n",
    "    date_given = dt.strptime(row[1], '%d.%m.%Y')\n",
    "    dates_start.append(date_given - td(0.75))\n",
    "    daily_precip.append(float(row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second step: A quick and dirty plot of the precipitation during this period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=96)\n",
    "plt.bar(dates_start, daily_precip, width=0.8)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.savefig('d1s2/ex2_step1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side remark: Comparing datetime object with/without time zone information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates, created through num2date, does contain time zone information, \n",
    "# where as those in dates_start, created through strptime, do not\n",
    "print(dates[0], dates_start[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will yield an error, because those two types of datetime are not comparable\n",
    "dates[0] > dates_start[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third and final step: Putting everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module for dealing with time zones\n",
    "import pytz\n",
    "\n",
    "# Then combining everything together, considering the period 15 September - 31 October\n",
    "mask_precip = np.array([date >= dt(2018,9,15) and date < dt(2018,11,1) for date in dates_start], dtype='bool')\n",
    "mask_runoff = np.array([date >= dt(2018,9,15,tzinfo=pytz.utc) and date < dt(2018,11,1,tzinfo=pytz.utc) for date in dates], dtype='bool')\n",
    "dates = np.array(dates)\n",
    "dates_start = np.array(dates_start)\n",
    "daily_precip = np.array(daily_precip)\n",
    "\n",
    "fig = plt.figure(figsize=(9.6, 4.8), dpi=96)\n",
    "\n",
    "plt.semilogy(dates[mask_runoff], data[mask_runoff,4], color='0.4', label='Median') # Median\n",
    "plt.semilogy(dates[mask_runoff], data[mask_runoff,2], color='C1', label='Observed') # The actual flow\n",
    "plt.fill_between(dates[mask_runoff], data[mask_runoff,3], data[mask_runoff,5], color='0.85', label='Interquartile range') # 25 and 75-percentile\n",
    "plt.ylabel('Runoff at Bulken [m³/s]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "ax2.bar(dates_start[mask_precip], daily_precip[mask_precip], width=0.9, alpha=0.5, color='C0')\n",
    "ax2.set_ylabel('Daily precip. at Bulken [mm]', color='C0')\n",
    "ax2.tick_params(axis='y', labelcolor='C0')\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.savefig('d1s2/ex2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "cf3f4aa4a82f4e5782f6264ed9b08390",
   "lastKernelId": "aadefa37-f530-462d-9a54-09067b980fa9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
