{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, after lunch: From text files to plots\n",
    "\n",
    "In this session, we will learn how to read text files and extract relevant information. We will also create plots using the python library ``matplotlib``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    " * test driven development\n",
    " * some examples with crafted errors\n",
    " * making use of introspection techniques? dir(), help(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('d1s2/Dovre1-Snoheim.txt', 'r')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines[0]) # first line of the file\n",
    "print(lines[-1]) # final line of the file, note the negative indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing\n",
    "Reading a file with `readlines()` gives us a list of strings, one for each line of the file. In this case each line is composed of a date and time followed by four floating point numbers. \n",
    "\n",
    "In order to do anything interesting with the data we need to interpret the strings as dates and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import dateutil.parser # powerful datetime string parsing\n",
    "# store data in lists, one for each column of the file\n",
    "dates = []\n",
    "temp = []\n",
    "ff = []\n",
    "dd = []\n",
    "for line in lines:\n",
    "    line = line.split() # splits a string into substrings by spaces\n",
    "    datetime_string = ' '.join(line[:2]) # the first two substrings contain time and date\n",
    "    dates.append(dt.strptime(datetime_string, '%d.%m.%Y %H:%M:%S'))\n",
    "    # dates.append(dateutil.parser.parse(datetime_string)) # parsing without explicit format string\n",
    "    temp.append(float(line[3])) # convrts a string into a float\n",
    "    ff.append(float(line[4]))\n",
    "    dd.append(float(line[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dates), dates[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Read and interpret the tile rro_Bulken.txt\n",
    "For this exercise you are going to read a file and do some analysis yourself. Start by printing the file to become familiar with its format. Then write a program to answer the following questions:\n",
    "* On how many days did the runoff exceed 300 m³/s?\n",
    "* On how many days did the runoff exceed the climatological median flow and the 75-percentile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('d1s2/rro_Bulken.txt', 'r', encoding='latin1')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "dates = []\n",
    "runoff = []\n",
    "p50 = []\n",
    "p75 = []\n",
    "for line in lines[2:]:\n",
    "    line = line.split()\n",
    "    dates.append(dt.strptime(line[0], '%d%m%Y'))\n",
    "    if line[2] == '----':\n",
    "        line[2] = 'NaN'\n",
    "    runoff.append(float(line[2]))\n",
    "    p50.append(float(line[4]))\n",
    "    p75.append(float(line[3]))\n",
    "\n",
    "l = len(runoff)\n",
    "print('Exceed 300 m3/s:', sum([r > 300 for r in runoff]), 'of', l)\n",
    "print('Exceed median:', sum([r > m for r, m in zip(runoff, p50)]), 'of', l)\n",
    "print('Exceed 75p:', sum([r > p for r, p in zip(runoff, p75)]), 'of', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite repetitive! There must be a simpler solution to this.\n",
    "\n",
    "## Reading text files using numpy.loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('d1s2/Dovre1-Snoheim.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires some custom functions to parse the date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta as td\n",
    "\n",
    "DT_REF = dt(1970,1,1)\n",
    "def parse_time(ibytes):\n",
    "    ''' Converts a bytes object into a float representing a date and time\n",
    "    \n",
    "    We need to return a float instead of a datetime, as the variable type \n",
    "    within a numpy array needs to be homogeneous.\n",
    "    \n",
    "    To convert the date to a float, we return the number of seconds since \n",
    "    a reference time given by DT_REF.\n",
    "    '''\n",
    "    \n",
    "    # Convert bytes to string\n",
    "    istr = ibytes.decode('latin1')\n",
    "    # Convert string to datetime\n",
    "    date = dt.strptime(istr, '%d.%m.%Y %H:%M:%S')\n",
    "    # Return number of seconds between DT_REF and date\n",
    "    return (date - DT_REF).total_seconds()\n",
    "\n",
    "def float_to_date(val):\n",
    "    ''' Convert a float back to datetime \n",
    "    \n",
    "    Consistently to ``parse_time'', ``val'' is expected to contain the\n",
    "    number of seconds since DT_REF. We can then use the timedelta object to \n",
    "    add the given number of seconds to DT_REF and return the resulting\n",
    "    ``datetime'' object.\n",
    "    '''\n",
    "    return DT_REF + td(0,val)\n",
    "\n",
    "data = np.loadtxt('d1s2/Dovre1-Snoheim.txt', delimiter='\\t', converters={\n",
    "    0: parse_time\n",
    "})\n",
    "print(data.shape)\n",
    "print(data[0], float_to_date(data[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, manually parsing the time like shown here is quite tedious and error-prone. Fortunately, there is a more straight-forward version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import bytespdate2num, num2date\n",
    "data = np.loadtxt('d1s2/Dovre1-Snoheim.txt', delimiter='\\t', converters={\n",
    "    0: bytespdate2num('%d.%m.%Y %H:%M:%S')\n",
    "})\n",
    "print(data.shape)\n",
    "print(data[0], num2date(data[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [num2date(date) for date in data[:,0]]\n",
    "airtemp = data[:,2]\n",
    "windspeed = data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dates, airtemp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "timeslice = slice(800, 3000)\n",
    "plt.plot(dates[timeslice], airtemp[timeslice])\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.ylabel('Temperature [°C]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dates[timeslice], airtemp[timeslice], color='C0') # First color of the standard cycle\n",
    "ax1 = plt.gca()\n",
    "ax1.set_ylabel('Temperature [°C]', color='C0')\n",
    "ax1.tick_params(axis='y', labelcolor='C0')\n",
    "\n",
    "ax2 = plt.twinx() # A new axes object sharing the x-axis with the original\n",
    "ax2.plot(dates[timeslice], windspeed[timeslice], color='C1') # Second color of the standard cycle\n",
    "ax2.set_ylabel('Wind speed [m/s]', color='C1')\n",
    "ax2.tick_params(axis='y', labelcolor='C1')\n",
    "\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\")) # needs to be done after the twinx\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=96) # Defining the figure size \n",
    "\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(dates[timeslice], airtemp[timeslice], color='C0', alpha=0.7) # Transparency for better visibility\n",
    "ax1.set_ylabel('Temperature [°C]', color='C0') \n",
    "ax1.tick_params(axis='y', labelcolor='C0')\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "ax2.plot(dates[timeslice], windspeed[timeslice], color='C1', alpha=0.7)\n",
    "ax2.set_ylabel('Wind speed [m/s]', color='C1')\n",
    "ax2.tick_params(axis='y', labelcolor='C1')\n",
    "\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Try to recreate the following plot based on the runoff data from Bulken\n",
    "\n",
    " * Use numpy.loadtxt to read the file and parse the dates\n",
    " * The shaded area shows the interval between the 25 and the 75 percentile\n",
    " * The functions ``plt.fill_between``, ``plt.semilogy`` and ``plt.legend`` might be helpful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_to_NaN(istr):\n",
    "    ''' Convert a string containing a number to a float, interpreting unparsible strings as NaN '''\n",
    "    \n",
    "    try:\n",
    "        val = float(istr)\n",
    "    except ValueError:\n",
    "        val = float('NaN')\n",
    "    \n",
    "    return val\n",
    "\n",
    "data = np.loadtxt('d1s2/rro_Bulken.txt', encoding='latin1', converters={\n",
    "    0: strpdate2num('%d%m%Y'),\n",
    "    1: missing_to_NaN,\n",
    "    2: missing_to_NaN,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [num2date(date) for date in data[:,0]]\n",
    "\n",
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=96)\n",
    "\n",
    "plt.semilogy(dates, data[:,4], color='0.4', label='Median') # Median\n",
    "plt.semilogy(dates, data[:,2], color='C1', label='Observed') # The actual flow\n",
    "plt.fill_between(dates, data[:,3], data[:,5], color='0.85', label='Interquartile range') # 25 and 75-percentile\n",
    "\n",
    "plt.ylabel('Runoff at Bulken [m³/s]')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension of the exercise: How does that fit with observed precipitation?\n",
    "\n",
    "Small extra challenge: Daily rainfall is defined by MetNorway between 06 UTC the preceeding day to 06 UTC of the given day. Make sure that the precipitation bars are located such along the time axis that the period in which the precipitation is observed matches the time interval covered by the bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual parsing necessary, np.loadtxt does not support footers\n",
    "f = open('d1s2/rr24_Bulken.txt', encoding='utf8')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "dates_start = [] # beginning of the observation intervals\n",
    "daily_precip = [] # observed values\n",
    "# Skip 21 header rows and 12 footer rows\n",
    "for row in lines[21:-12]:\n",
    "    row = row.split()\n",
    "    date_given = dt.strptime(row[1], '%d.%m.%Y')\n",
    "    dates_start.append(date_given - td(0.75))\n",
    "    daily_precip.append(float(row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a quick and dirty plot of the precipitation during this period\n",
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=96)\n",
    "plt.bar(dates_start, daily_precip, width=0.8)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then combining everything together, considering the period 15 September - 31 October\n",
    "mask_precip = np.array([date >= dt(2018,9,15) and date < dt(2018,11,1) for date in dates_start], dtype='bool')\n",
    "mask_runoff = np.array([date >= dt(2018,9,15) and date < dt(2018,11,1) for date in dates], dtype='bool')\n",
    "dates = np.array(dates)\n",
    "dates_start = np.array(dates_start)\n",
    "daily_precip = np.array(daily_precip)\n",
    "\n",
    "fig = plt.figure(figsize=(9.6, 4.8), dpi=96)\n",
    "\n",
    "plt.semilogy(dates[mask_runoff], data[mask_runoff,4], color='0.4', label='Median') # Median\n",
    "plt.semilogy(dates[mask_runoff], data[mask_runoff,2], color='C1', label='Observed') # The actual flow\n",
    "plt.fill_between(dates[mask_runoff], data[mask_runoff,3], data[mask_runoff,5], color='0.85', label='Interquartile range') # 25 and 75-percentile\n",
    "plt.ylabel('Runoff at Bulken [m³/s]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "ax2.bar(dates_start[mask_precip], daily_precip[mask_precip], width=0.9, alpha=0.5, color='C0')\n",
    "ax2.set_ylabel('Daily precip. at Bulken [mm]', color='C0')\n",
    "ax2.tick_params(axis='y', labelcolor='C0')\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "cf3f4aa4a82f4e5782f6264ed9b08390",
   "lastKernelId": "aadefa37-f530-462d-9a54-09067b980fa9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
